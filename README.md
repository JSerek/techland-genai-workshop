# GenAI Workshop: Text Classification with LLMs

**Warsztaty: Wykorzystanie GenAI w jakoÅ›ciowej analizie danych**

Projekt szkoleniowy do nauki klasyfikacji tekstÃ³w za pomocÄ… modeli jÄ™zykowych poprzez API, z wykorzystaniem danych z recenzji Steam gry "Dying Light 2: The Beast".

---

## ğŸ“‹ Opis Projektu

Ten projekt zostaÅ‚ stworzony na potrzeby 8-godzinnych warsztatÃ³w dotyczÄ…cych wykorzystania GenAI do analizy danych jakoÅ›ciowych. Uczestnicy uczÄ… siÄ™:

- **Promptowania LLM** do klasyfikacji tekstu
- **Structured Output** z wykorzystaniem Pydantic
- **Chain-of-Thought** reasoning
- **Few-shot learning** techniques
- **Ewaluacji i optymalizacji** promptÃ³w

### Program WarsztatÃ³w

1. âœ… **Wprowadzenie** - Postawy i myÅ›lenie sprzyjajÄ…ce wykorzystaniu GenAI
2. âœ… **Problem klasyfikacji** - Eksploracja vs. Klasyfikacja danych jakoÅ›ciowych
3. ğŸ”„ **Iteracja 1**: Podstawowe promptowanie
4. ğŸ”„ **Iteracja 2**: Structured Output (Pydantic)
5. ğŸ”„ **Iteracja 3**: Chain-of-Thought
6. ğŸ”„ **Iteracja 4**: Zero/One/Few-shot learning
7. ğŸ† **Gamifikacja**: Konkurs na najlepszy klasyfikator

---

## ğŸ—‚ï¸ Struktura Projektu

```
szkolenie_techland/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                    # Surowe dane ze scrapera (gitignored)
â”‚   â”œâ”€â”€ processed/              # Oczyszczone dane (gitignored)
â”‚   â””â”€â”€ evaluation/             # Zbiory ewaluacyjne
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_data_collection.ipynb       # âœ… Scraping + eksploracja danych
â”‚   â”œâ”€â”€ 02_data_cleaning.ipynb         # ğŸ”„ Przygotowanie datasetu
â”‚   â”œâ”€â”€ 03_iteration1_basic.ipynb      # ğŸ”„ Warsztaty: Iteracja 1
â”‚   â”œâ”€â”€ 04_iteration2_structured.ipynb # ğŸ”„ Warsztaty: Iteracja 2
â”‚   â”œâ”€â”€ 05_iteration3_cot.ipynb        # ğŸ”„ Warsztaty: Iteracja 3
â”‚   â””â”€â”€ 06_iteration4_few_shot.ipynb   # ğŸ”„ Warsztaty: Iteracja 4
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ scraper/                # âœ… ModuÅ‚y do scrapingu Steam
â”‚   â”œâ”€â”€ classification/         # ğŸ”„ Klasyfikacja z LLM
â”‚   â”œâ”€â”€ evaluation/             # ğŸ”„ Metryki i wizualizacje
â”‚   â””â”€â”€ utils/                  # âœ… Konfiguracja i narzÄ™dzia
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ scrape_reviews.py       # âœ… CLI do szybkiego scrapingu
â”œâ”€â”€ requirements.txt            # âœ… ZaleÅ¼noÅ›ci
â””â”€â”€ README.md                   # âœ… Dokumentacja
```

---

## ğŸš€ Quickstart

### ğŸ‘©â€ğŸ’» Uczestnicy warsztatÃ³w â€” Google Colab (zalecane)

Nie musisz nic instalowaÄ‡ lokalnie. Wszystko dziaÅ‚a w przeglÄ…darce.

#### Krok 1: Skonfiguruj API w Colab Secrets

W kaÅ¼dym notebooku Colab masz menu po lewej stronie z ikonÄ… ğŸ”‘ **Secrets**.
Dodaj tam trzy sekrety (prowadzÄ…cy poda wartoÅ›ci na poczÄ…tku warsztatÃ³w):

| Nazwa sekretu | Opis |
|---|---|
| `VERTEX_AI_API_KEY` | Klucz API do modelu Gemini |
| `VERTEX_AI_BASE_URL` | Endpoint URL Vertex AI |
| `MODEL_NAME` | Nazwa modelu (np. `google/gemini-2.5-flash-lite`) |

> ğŸ’¡ Sekrety sÄ… bezpieczne â€” nie sÄ… widoczne w notebooku ani nie trafiajÄ… do repozytorium.

#### Krok 2: OtwÃ³rz notebook

Kliknij w link do notebooka ktÃ³ry chcesz otworzyÄ‡ (linki poda prowadzÄ…cy).
Alternatywnie: wejdÅº na [colab.research.google.com](https://colab.research.google.com) â†’ File â†’ Open notebook â†’ GitHub â†’ wklej URL repo.

#### Krok 3: Uruchom pierwsze 3 komÃ³rki setup

KaÅ¼dy notebook zaczyna siÄ™ od komÃ³rek setup ktÃ³re:
1. KlonujÄ… repozytorium z GitHub
2. InstalujÄ… biblioteki (`openai`, `instructor`, `pydantic`, ...)
3. WczytujÄ… API key z Secrets

> âš ï¸ **Uwaga:** Pierwsze uruchomienie trwa ~1 minutÄ™ (instalacja bibliotek). Kolejne sÄ… szybkie.

---

### ğŸ—ï¸ ProwadzÄ…cy/Deweloperzy â€” lokalna instalacja

```bash
# Sklonuj repozytorium
git clone https://github.com/JSerek/techland-genai-workshop.git
cd szkolenie_techland

# UtwÃ³rz Å›rodowisko wirtualne
python3 -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# Zainstaluj zaleÅ¼noÅ›ci
pip install -r requirements.txt
```

Ustaw zmienne Å›rodowiskowe (lub wpisz bezpoÅ›rednio w notebooku):
```bash
export VERTEX_AI_API_KEY="..."
export VERTEX_AI_BASE_URL="https://us-central1-aiplatform.googleapis.com/v1beta1/projects/PROJECT_ID/locations/us-central1/endpoints/openapi"
export MODEL_NAME="google/gemini-2.5-flash-lite"
```

Przygotuj dane warsztatowe (uruchom raz przed warsztatami):
```bash
# Generuje data/processed/workshop_sample.csv i szkielet golden_dataset.json
python scripts/prepare_workshop_data.py

# Przetestuj caÅ‚y pipeline
python scripts/test_pipeline.py \
  --provider vertex_ai \
  --api-key "$VERTEX_AI_API_KEY" \
  --base-url "$VERTEX_AI_BASE_URL" \
  --model "$MODEL_NAME"
```

---

## ğŸ“Š Steam Review Scraper

### FunkcjonalnoÅ›ci

- âœ… **Bez klucza API** - wykorzystuje publiczny endpoint Steam
- âœ… **Rate limiting** - bezpieczne tempo ~2 req/s
- âœ… **Checkpointing** - moÅ¼liwoÅ›Ä‡ wznowienia po przerwaniu
- âœ… **Pydantic validation** - strukturyzowane dane
- âœ… **Multi-format export** - JSON, CSV, Parquet
- âœ… **Progress tracking** - pasek postÄ™pu z tqdm
- âœ… **Retry logic** - automatyczne ponowienie przy bÅ‚Ä™dach

### PrzykÅ‚ad UÅ¼ycia (Python)

```python
from src.scraper.steam_api import SteamReviewScraper

# Inicjalizacja
scraper = SteamReviewScraper(app_id=3008130)

# Scraping
reviews = scraper.scrape_reviews(
    max_reviews=10000,
    review_type="negative",
    language="english",
    save_checkpoints=True,
)

# Statystyki
stats = scraper.get_stats_summary()
print(stats)
```

### CLI Help

```bash
python scripts/scrape_reviews.py --help
```

**DostÄ™pne parametry:**
- `--app-id` - Steam App ID (default: 3008130)
- `--max-reviews` - Max liczba recenzji (default: 10000)
- `--review-type` - all/positive/negative (default: negative)
- `--language` - JÄ™zyk recenzji (default: english)
- `--formats` - Formaty eksportu (json, csv, parquet)
- `--resume` - WznÃ³w z checkpointu
- `--no-checkpoints` - WyÅ‚Ä…cz zapisywanie checkpointÃ³w

---

## ğŸ“ Dla UczestnikÃ³w WarsztatÃ³w

### Przed warsztatami (zrÃ³b to dzieÅ„ wczeÅ›niej):

1. **Upewnij siÄ™ Å¼e masz konto Google** â€” potrzebne do Google Colab
2. **WejdÅº na [colab.research.google.com](https://colab.research.google.com)** i sprawdÅº Å¼e dziaÅ‚a
3. Nic wiÄ™cej nie trzeba instalowaÄ‡ ğŸ‰

### Plan warsztatÃ³w:

| # | Notebook | Temat | Czas |
|---|----------|-------|------|
| 02 | `02_data_preparation` | Eksploracja danych ze Steam | 30 min |
| 03 | `03_iteration1_basic_prompting` | Zero-shot: pierwsza klasyfikacja | 35 min |
| 04 | `04_iteration2_structured_output` | Pydantic + Instructor | 45 min |
| 05 | `05_iteration3_chain_of_thought` | Chain-of-Thought reasoning | 45 min |
| 06 | `06_iteration4_few_shot` | Few-shot + konkurs ğŸ† | 45 min |

KaÅ¼da iteracja zawiera:
- ğŸ“š Wprowadzenie teoretyczne (w komÃ³rkach markdown)
- ğŸ’» Szablon kodu do uzupeÅ‚nienia
- ğŸ¯ Ä†wiczenie praktyczne
- ğŸ“Š EwaluacjÄ™ accuracy wzglÄ™dem golden dataset

---

## ğŸ“¦ ZaleÅ¼noÅ›ci

### Core
- `requests` - HTTP requests do Steam API
- `pydantic` - Walidacja i strukturyzacja danych
- `pandas` - Analiza danych
- `tqdm` - Progress bars

### Notebooks
- `jupyter` - Interaktywne notebooki
- `matplotlib`, `seaborn`, `plotly` - Wizualizacje

### Optional
- `pyarrow` - Wsparcie dla Parquet
- `rich` - Lepsze CLI formatowanie

---

## ğŸ”§ Konfiguracja

GÅ‚Ã³wny plik konfiguracyjny: `src/utils/config.py`

**Kluczowe ustawienia:**
```python
DYING_LIGHT_BEAST_APP_ID = 3008130
TARGET_NEGATIVE_REVIEWS = 100_000
RATE_LIMIT_DELAY = 0.5  # sekundy miÄ™dzy requestami
MAX_RETRIES = 3
CHECKPOINT_INTERVAL = 10_000  # co ile recenzji zapisaÄ‡ checkpoint
```

---

## ğŸ“ˆ Dane

### Steam Reviews - Dying Light 2: The Beast

**Metadane zapisywane dla kaÅ¼dej recenzji:**
- `review_id` - Unikalny ID recenzji
- `review_text` - TreÅ›Ä‡ recenzji
- `sentiment` - positive/negative
- `voted_up` - True/False
- `votes_up` - Liczba gÅ‚osÃ³w "helpful"
- `playtime_hours` - Godziny gry autora
- `created_date` - Data publikacji
- `language` - JÄ™zyk recenzji
- `steam_purchase` - Czy zakup na Steam
- `early_access` - Czy napisane w early access

### PrzykÅ‚adowa recenzja:

```json
{
  "review_id": "218102167",
  "sentiment": "negative",
  "voted_up": false,
  "votes_up": 3,
  "playtime_hours": 24.8,
  "review_text": "The worst game in the series.",
  "created_date": "2026-02-11T21:50:29",
  "language": "english"
}
```

---

## ğŸš¨ Uwagi Techniczne

### Steam API

- **Endpoint**: `https://store.steampowered.com/appreviews/{app_id}`
- **Limit**: Brak oficjalnego limitu dla publicznego endpointu
- **Rate limiting**: Zalecane max 2 req/s
- **Bez autentykacji**: Nie wymaga Steam Developer Key
- **ToS**: UÅ¼ywaj odpowiedzialnie, nie przeciÄ…Å¼aj serwerÃ³w

### Checkpointing

Checkpointy sÄ… zapisywane w `data/raw/checkpoints/` co 10,000 recenzji.

Aby wznowiÄ‡ przerwany scraping:
```bash
python scripts/scrape_reviews.py --resume
```

### Troubleshooting

**Problem: `429 Too Many Requests`**
- RozwiÄ…zanie: ZwiÄ™ksz `RATE_LIMIT_DELAY` w config.py

**Problem: Pydantic validation errors**
- RozwiÄ…zanie: Steam API czasem zwraca niespÃ³jne dane, retry logic powinien to obsÅ‚uÅ¼yÄ‡

**Problem: Brak recenzji w okreÅ›lonym jÄ™zyku**
- RozwiÄ…zanie: ZmieÅ„ `language='all'` aby pobraÄ‡ wszystkie jÄ™zyki

---

## ğŸ¯ Roadmap

### Etap 1: Data Collection âœ…
- [x] Steam scraper
- [x] Data models (Pydantic)
- [x] Export do multiple formats
- [x] Interactive notebook

### Etap 2: Data Preparation ğŸ”„
- [ ] Data cleaning notebook
- [ ] Remove duplicates
- [ ] Filter low-quality reviews
- [ ] Balance dataset
- [ ] Create evaluation set

### Etap 3: Classification Setup ğŸ”„
- [ ] Define classification categories
- [ ] LLM client wrapper
- [ ] Prompt templates
- [ ] Structured output schemas

### Etap 4: Workshops ğŸ”„
- [ ] Iteration 1: Basic prompting
- [ ] Iteration 2: Structured outputs
- [ ] Iteration 3: Chain-of-thought
- [ ] Iteration 4: Few-shot learning

### Etap 5: Evaluation & Viz ğŸ”„
- [ ] Custom metrics
- [ ] Confusion matrices
- [ ] Interactive dashboards
- [ ] Leaderboard system

---

## ğŸ‘¤ Autor

**Jakub Serek**
Szkolenie dla: Techland

## ğŸ“„ Licencja

MateriaÅ‚y szkoleniowe - uÅ¼ytek edukacyjny.

---

## ğŸ™ Acknowledgments

- **Steam** - za publiczne API do recenzji
- **Dying Light 2: The Beast** - dane treningowe
- **Anthropic/OpenAI** - modele LLM do klasyfikacji

---

## ğŸ“ Kontakt / Support

W razie pytaÅ„ podczas warsztatÃ³w - pytaj prowadzÄ…cego!

**Przydatne linki:**
- [Steam Web API Documentation](https://partner.steamgames.com/doc/webapi_overview)
- [Pydantic Documentation](https://docs.pydantic.dev/)
- [Anthropic Claude API](https://docs.anthropic.com/)

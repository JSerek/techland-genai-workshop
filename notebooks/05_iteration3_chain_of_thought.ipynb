{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üß† Iteracja 3: Chain-of-Thought (CoT) Prompting\n",
    "\n",
    "**Czas:** ~45 minut  \n",
    "**Poziom:** ≈öredniozaawansowany\n",
    "\n",
    "---\n",
    "\n",
    "## Cel iteracji\n",
    "\n",
    "Poprawiƒá accuracy klasyfikacji przez wymuszenie na modelu **jawnego rozumowania krok po kroku** przed podaniem ostatecznej odpowiedzi.\n",
    "\n",
    "---\n",
    "\n",
    "## Teoria: Chain-of-Thought\n",
    "\n",
    "**Chain-of-Thought (CoT)** to technika promptowania, w kt√≥rej instruujemy model, ≈ºeby przed podaniem odpowiedzi wypisa≈Ç sw√≥j tok rozumowania.\n",
    "\n",
    "### Dlaczego CoT dzia≈Ça?\n",
    "\n",
    "Modele jƒôzykowe generujƒÖ tekst token po tokenie. Kiedy model \"pisze swoje my≈õli\", ka≈ºdy wygenerowany token staje siƒô kontekstem dla nastƒôpnego - model dos≈Çownie **\"my≈õli g≈Ço≈õno\"** i mo≈ºe siƒô korygowaƒá w trakcie.\n",
    "\n",
    "```\n",
    "Bez CoT:\n",
    "  Recenzja ‚Üí [model] ‚Üí \"bug\"\n",
    "  \n",
    "Z CoT:\n",
    "  Recenzja ‚Üí [model] ‚Üí \"Recenzja m√≥wi o crashach i FPS drops.  \n",
    "                        Crasze to kategoria bug, FPS to performance.\n",
    "                        Wniosek: bug, performance\" ‚Üí [\"bug\", \"performance\"]\n",
    "```\n",
    "\n",
    "### Rodzaje CoT\n",
    "\n",
    "| Typ | Opis | Jak u≈ºyƒá |\n",
    "|-----|------|----------|\n",
    "| **Zero-shot CoT** | Magiczne zdanie w prompcie | `\"Think step by step\"` lub `\"Przemy≈õl to krok po kroku\"` |\n",
    "| **Manual CoT** | Jawny format rozumowania | Pole `reasoning: str` przed `categories` w Pydantic |\n",
    "| **Self-consistency** | Kilka przebieg√≥w + g≈Çosowanie | Zaawansowane - nie dzi≈õ |\n",
    "\n",
    "### Kluczowa zasada przy Pydantic + CoT:\n",
    "\n",
    "> **Pole `reasoning` musi byƒá PRZED `categories`** w modelu Pydantic.\n",
    "> Model generuje pola w kolejno≈õci ich definicji.\n",
    "> Je≈õli `categories` jest pierwsze, model podaje kategoriƒô PRZED rozumowaniem - efekt odwrotny!\n",
    "\n",
    "```python\n",
    "# ‚ùå Z≈ÅE: categories przed reasoning\n",
    "class Bad(BaseModel):\n",
    "    categories: list[str]\n",
    "    reasoning: str  # Model ju≈º podjƒÖ≈Ç decyzjƒô!\n",
    "\n",
    "# ‚úÖ DOBRE: reasoning przed categories  \n",
    "class Good(BaseModel):\n",
    "    reasoning: str   # Model \"my≈õli\" najpierw\n",
    "    categories: list[str]  # Potem decyduje\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Setup - ≈õrodowisko\n",
    "\n",
    "Ta kom√≥rka wykrywa czy jeste≈õ w **Google Colab** czy lokalnie, a nastƒôpnie:\n",
    "1. Klonuje repozytorium z GitHub (tylko Colab)\n",
    "2. Instaluje wymagane biblioteki\n",
    "3. Konfiguruje ≈õcie≈ºki import√≥w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "# Wykryj ≈õrodowisko\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "\n",
    "print(f\"{'üü° Google Colab' if IN_COLAB else 'üíª Lokalne ≈õrodowisko'}\")\n",
    "\n",
    "# ============================================================\n",
    "# KONFIGURACJA REPO (zmie≈Ñ URL na w≈Ça≈õciwe przed warsztatami)\n",
    "# ============================================================\n",
    "REPO_URL = \"https://github.com/JSerek/techland-genai-workshop.git\"\n",
    "REPO_DIR = Path(\"/content/szkolenie_techland\") if IN_COLAB else Path(\".\").resolve().parent\n",
    "# ============================================================\n",
    "\n",
    "if IN_COLAB:\n",
    "    if not REPO_DIR.exists():\n",
    "        print(f\"üì• Klonujƒô repo...\")\n",
    "        subprocess.run([\"git\", \"clone\", REPO_URL, str(REPO_DIR)], check=True)\n",
    "        print(\"‚úÖ Repo sklonowane\")\n",
    "    else:\n",
    "        print(\"üîÑ Aktualizujƒô repo (git pull)...\")\n",
    "        subprocess.run([\"git\", \"-C\", str(REPO_DIR), \"pull\"], check=True)\n",
    "\n",
    "    # Dodaj repo do sys.path\n",
    "    sys.path.insert(0, str(REPO_DIR))\n",
    "\n",
    "    # Zainstaluj zale≈ºno≈õci\n",
    "    print(\"üì¶ Instalujƒô biblioteki...\")\n",
    "    subprocess.run(\n",
    "        [sys.executable, \"-m\", \"pip\", \"install\", \"-r\", str(REPO_DIR / \"requirements.txt\"), \"-q\"],\n",
    "        check=True\n",
    "    )\n",
    "    print(\"‚úÖ Biblioteki zainstalowane\")\n",
    "else:\n",
    "    # Lokalnie: dodaj root projektu do sys.path\n",
    "    sys.path.insert(0, str(REPO_DIR))\n",
    "    print(f\"üìÇ ≈öcie≈ºka projektu: {REPO_DIR}\")\n",
    "\n",
    "print(\"\\n‚úÖ Setup zako≈Ñczony\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# üîë Konfiguracja API\n",
    "# W Google Colab: dodaj sekrety w menu po lewej (üîë ikona)\n",
    "#   Nazwy sekret√≥w: VERTEX_AI_API_KEY, VERTEX_AI_BASE_URL, MODEL_NAME\n",
    "#\n",
    "# Lokalnie: ustaw zmienne ≈õrodowiskowe lub wpisz warto≈õci bezpo≈õrednio\n",
    "# ============================================================\n",
    "\n",
    "if IN_COLAB:\n",
    "    from google.colab import userdata\n",
    "    API_KEY   = userdata.get(\"VERTEX_AI_API_KEY\")\n",
    "    BASE_URL  = userdata.get(\"VERTEX_AI_BASE_URL\")\n",
    "    MODEL_NAME = userdata.get(\"MODEL_NAME\") or \"google/gemini-2.5-flash-lite\"\n",
    "else:\n",
    "    import os\n",
    "    API_KEY   = os.environ.get(\"VERTEX_AI_API_KEY\", \"TODO: wklej API key\")\n",
    "    BASE_URL  = os.environ.get(\"VERTEX_AI_BASE_URL\", \"TODO: wklej endpoint URL\")\n",
    "    MODEL_NAME = os.environ.get(\"MODEL_NAME\", \"google/gemini-2.5-flash-lite\")\n",
    "\n",
    "# Walidacja\n",
    "if not API_KEY or API_KEY == \"TODO: wklej API key\":\n",
    "    print(\"‚ùå Brak API_KEY! Dodaj sekret 'VERTEX_AI_API_KEY' w Colab Secrets.\")\n",
    "elif not BASE_URL or BASE_URL == \"TODO: wklej endpoint URL\":\n",
    "    print(\"‚ùå Brak BASE_URL! Dodaj sekret 'VERTEX_AI_BASE_URL' w Colab Secrets.\")\n",
    "else:\n",
    "    print(f\"‚úÖ API skonfigurowane: {MODEL_NAME}\")\n",
    "    print(f\"   Endpoint: {BASE_URL[:60]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Konfiguracja klienta LLM - dane pobrane z Secrets w kom√≥rce powy≈ºej\n",
    "from src.utils.llm_client import create_client, LLMProvider\n",
    "\n",
    "PROVIDER = LLMProvider.VERTEX_AI  # Zmie≈Ñ je≈õli u≈ºywasz innego providera\n",
    "\n",
    "client = create_client(\n",
    "    provider=PROVIDER,\n",
    "    api_key=API_KEY,\n",
    "    base_url=BASE_URL,\n",
    ")\n",
    "print(f\"‚úÖ Klient LLM gotowy: {PROVIDER.value} / {MODEL_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Optional\n",
    "\n",
    "from src.evaluation.evaluator import evaluate_trial, compare_trials, MatchStrategy\n",
    "\n",
    "\n",
    "# Kategorie tematyczne\n",
    "CATEGORIES = [\n",
    "    \"gameplay\",       # Mechaniki rozgrywki, walka, parkour, sterowanie, balans\n",
    "    \"story\",          # Fabu≈Ça, postacie, dialogi, scenariusz\n",
    "    \"bugs\",           # Crashe, glitche, b≈Çƒôdy, problemy techniczne\n",
    "    \"performance\",    # FPS, lag, stuttering, optymalizacja ≈Çadowania\n",
    "    \"content\",        # Ilo≈õƒá contentu, d≈Çugo≈õƒá gry, powtarzalno≈õƒá\n",
    "    \"graphics\",       # Grafika, wizualia, animacje\n",
    "    \"audio\",          # Muzyka, d≈∫wiƒôki, voice acting\n",
    "    \"price\",          # Cena, warto≈õƒá za pieniƒÖdze, DLC\n",
    "]\n",
    "categories_str = ', '.join(f'\"{{c}}\"' for c in CATEGORIES)\n",
    "\n",
    "print('‚úÖ Biblioteki za≈Çadowane')\n",
    "print(f'Kategorie ({len(CATEGORIES)}): {categories_str}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = REPO_DIR / 'data'\n",
    "\n",
    "# Wczytaj golden dataset\n",
    "golden_path = DATA_DIR / 'evaluation' / 'golden_dataset.json'\n",
    "with open(golden_path) as f:\n",
    "    golden_data = json.load(f)\n",
    "\n",
    "golden_texts  = [item['review_text'] for item in golden_data]\n",
    "golden_labels = [item['labels']      for item in golden_data]\n",
    "\n",
    "print(f'‚úÖ Golden dataset: {len(golden_data)} recenzji')\n",
    "print(f'   Kategorie: {sorted(set(l for item in golden_data for l in item[\"labels\"]))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìã Golden Dataset\n",
    "\n",
    "Poni≈ºej 100 recenzji z przypisanymi kategoriami ‚Äî to nasz punkt odniesienia do ewaluacji.\n",
    "Model bƒôdzie klasyfikowa≈Ç te same recenzje, a my sprawdzimy czy jego wyniki zgadzajƒÖ siƒô z etykietami.\n",
    "\n",
    "| Kategoria | Opis |\n",
    "|-----------|------|\n",
    "| `gameplay` | Mechaniki rozgrywki, walka, parkour, sterowanie, balans |\n",
    "| `story` | Fabu≈Ça, postacie, dialogi, scenariusz |\n",
    "| `bugs` | Crashe, glitche, b≈Çƒôdy, problemy techniczne |\n",
    "| `performance` | FPS, lag, stuttering, optymalizacja |\n",
    "| `content` | Ilo≈õƒá contentu, d≈Çugo≈õƒá gry, powtarzalno≈õƒá |\n",
    "| `graphics` | Grafika, wizualia, animacje |\n",
    "| `audio` | Muzyka, d≈∫wiƒôki, voice acting |\n",
    "| `price` | Cena, warto≈õƒá za pieniƒÖdze, DLC |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "def show_golden_dataset(data: list[dict], max_text: int = 120) -> None:\n",
    "    \"\"\"Wy≈õwietla golden dataset jako sformatowanƒÖ tabelƒô HTML.\"\"\"\n",
    "    rows = []\n",
    "    for item in data:\n",
    "        text = item['review_text']\n",
    "        if len(text) > max_text:\n",
    "            text = text[:max_text] + '...'\n",
    "        # Ka≈ºda etykieta jako kolorowy badge\n",
    "        COLORS = {\n",
    "            'gameplay':    '#4C72B0', 'story':       '#DD8452',\n",
    "            'bugs':        '#55A868', 'performance': '#C44E52',\n",
    "            'content':     '#8172B2', 'graphics':    '#937860',\n",
    "            'audio':       '#DA8BC3', 'price':       '#8C8C8C',\n",
    "        }\n",
    "        badges = ' '.join(\n",
    "            f'<span style=\"background:{COLORS.get(l, \"#888\")};color:white;'\n",
    "            f'padding:2px 8px;border-radius:10px;font-size:11px;\">{l}</span>'\n",
    "            for l in item['labels']\n",
    "        )\n",
    "        rows.append(f'<tr><td style=\"text-align:center;color:#888;\">{item[\"id\"]}</td>'\n",
    "                    f'<td style=\"font-size:12px;\">{text}</td>'\n",
    "                    f'<td>{badges}</td></tr>')\n",
    "\n",
    "    html = f'''\n",
    "    <style>\n",
    "        .golden-table {{ border-collapse: collapse; width: 100%; font-family: sans-serif; }}\n",
    "        .golden-table th {{ background: #2d2d2d; color: white; padding: 8px 12px; text-align: left; }}\n",
    "        .golden-table td {{ padding: 6px 12px; border-bottom: 1px solid #eee; vertical-align: top; }}\n",
    "        .golden-table tr:hover td {{ background: #f9f9f9; }}\n",
    "    </style>\n",
    "    <table class=\"golden-table\">\n",
    "        <thead><tr>\n",
    "            <th style=\"width:40px\">#</th>\n",
    "            <th>Recenzja</th>\n",
    "            <th style=\"width:200px\">Kategorie</th>\n",
    "        </tr></thead>\n",
    "        <tbody>{''.join(rows)}</tbody>\n",
    "    </table>\n",
    "    '''\n",
    "    display(HTML(html))\n",
    "\n",
    "print(f'Golden dataset ‚Äî {len(golden_data)} recenzji:')\n",
    "show_golden_dataset(golden_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üî¨ Eksperyment: Zero-shot CoT\n",
    "\n",
    "Najprostsza forma CoT - jedno zdanie w prompcie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReviewClassification(BaseModel):\n",
    "    \"\"\"Klasyfikacja bez CoT (baseline z Iteracji 2).\"\"\"\n",
    "    categories: list[str] = Field(description=f\"Kategorie: {CATEGORIES}\")\n",
    "\n",
    "\n",
    "class ReviewClassificationCoT(BaseModel):\n",
    "    \"\"\"Klasyfikacja z Chain-of-Thought - reasoning PRZED categories.\"\"\"\n",
    "\n",
    "    reasoning: str = Field(\n",
    "        description=(\n",
    "            \"Krok po kroku analiza recenzji: \"\n",
    "            \"1) Co konkretnie opisuje recenzja? \"\n",
    "            \"2) Kt√≥re fragmenty wskazujƒÖ na poszczeg√≥lne kategorie? \"\n",
    "            \"3) Ostateczne uzasadnienie wyboru kategorii.\"\n",
    "        )\n",
    "    )\n",
    "    categories: list[str] = Field(\n",
    "        description=f\"Finalna lista kategorii po analizie. Dozwolone: {CATEGORIES}\"\n",
    "    )\n",
    "\n",
    "\n",
    "print(\"‚úÖ Modele zdefiniowane\")\n",
    "print(f\"ReviewClassification pola: {list(ReviewClassification.model_fields.keys())}\")\n",
    "print(f\"ReviewClassificationCoT pola: {list(ReviewClassificationCoT.model_fields.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Systemy prompt√≥w: bez CoT vs z CoT\n",
    "\n",
    "SYSTEM_PROMPT_BASELINE = f\"\"\"Klasyfikuj recenzjƒô gry do kategorii tematycznych.\n",
    "Dostƒôpne kategorie: {categories_str}\n",
    "Przypisz jednƒÖ lub wiƒôcej pasujƒÖcych kategorii.\"\"\"\n",
    "\n",
    "SYSTEM_PROMPT_COT = f\"\"\"Jeste≈õ ekspertem od analizy recenzji gier komputerowych.\n",
    "Klasyfikujesz recenzje do kategorii tematycznych.\n",
    "\n",
    "Dostƒôpne kategorie: {categories_str}\n",
    "\n",
    "Tw√≥j proces:\n",
    "1. Przeczytaj recenzjƒô uwa≈ºnie\n",
    "2. Zidentyfikuj konkretne elementy/problemy opisane w recenzji\n",
    "3. Dla ka≈ºdego elementu - okre≈õl odpowiadajƒÖcƒÖ kategoriƒô\n",
    "4. Podaj finalnƒÖ listƒô kategorii\n",
    "\n",
    "Przemy≈õl to krok po kroku przed podaniem ostatecznej odpowiedzi.\"\"\"\n",
    "\n",
    "USER_PROMPT = \"Recenzja do sklasyfikowania: {review_text}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo: por√≥wnanie baseline vs CoT na jednej recenzji\n",
    "test_review = review_texts[0]\n",
    "print(f\"Recenzja: '{test_review[:300]}'\\n\")\n",
    "\n",
    "# Baseline (bez CoT)\n",
    "result_baseline = client.chat.completions.create(\n",
    "    model=MODEL_NAME,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT_BASELINE},\n",
    "        {\"role\": \"user\", \"content\": USER_PROMPT.format(review_text=test_review)},\n",
    "    ],\n",
    "    response_model=ReviewClassification,\n",
    "    temperature=0.0,\n",
    ")\n",
    "\n",
    "# Z CoT\n",
    "result_cot = client.chat.completions.create(\n",
    "    model=MODEL_NAME,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT_COT},\n",
    "        {\"role\": \"user\", \"content\": USER_PROMPT.format(review_text=test_review)},\n",
    "    ],\n",
    "    response_model=ReviewClassificationCoT,\n",
    "    temperature=0.0,\n",
    ")\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"BASELINE (bez CoT):\")\n",
    "print(f\"  Kategorie: {result_baseline.categories}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"Z CHAIN-OF-THOUGHT:\")\n",
    "print(f\"  Rozumowanie: {result_cot.reasoning}\")\n",
    "print(f\"  Kategorie: {result_cot.categories}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ ƒÜwiczenie: Zoptymalizuj CoT prompt\n",
    "\n",
    "### Zadanie:\n",
    "Napisz w≈Çasny system prompt z Chain-of-Thought i sprawd≈∫ czy poprawia accuracy.\n",
    "\n",
    "**Eksperymenty do przeprowadzenia:**\n",
    "1. Zmie≈Ñ jƒôzyk promptu (EN vs PL)\n",
    "2. Dodaj przyk≈Çady toku rozumowania (manual CoT)\n",
    "3. Zmie≈Ñ sformu≈Çowanie krok√≥w analizy\n",
    "4. Dodaj instrukcjƒô sprawdzenia w≈Çasnej odpowiedzi: `\"Review your answer and correct any mistakes\"`\n",
    "5. Eksperymentuj z temperaturƒÖ (0.0 vs 0.3 vs 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# üñäÔ∏è  ƒÜWICZENIE: Tw√≥j CoT prompt\n",
    "# ============================================================\n",
    "\n",
    "MY_COT_SYSTEM_PROMPT = \"\"\"\n",
    "# TODO: Napisz sw√≥j system prompt z Chain-of-Thought\n",
    "\"\"\"\n",
    "\n",
    "# Opcjonalnie: w≈Çasny Pydantic model z innym polem reasoning\n",
    "# class MyCoTModel(BaseModel):\n",
    "#     ...\n",
    "\n",
    "print(\"Uzupe≈Çnij MY_COT_SYSTEM_PROMPT i przetestuj!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Por√≥wnanie: Iteracja 2 vs Iteracja 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "texts_to_classify = golden_texts if golden_texts else review_texts[:10]\n",
    "\n",
    "# Klasyfikacja CoT\n",
    "print(\"Klasyfikujƒô z Chain-of-Thought...\")\n",
    "predictions_cot = []\n",
    "for text in tqdm(texts_to_classify):\n",
    "    try:\n",
    "        result = client.chat.completions.create(\n",
    "            model=MODEL_NAME,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": SYSTEM_PROMPT_COT},\n",
    "                {\"role\": \"user\", \"content\": USER_PROMPT.format(review_text=text)},\n",
    "            ],\n",
    "            response_model=ReviewClassificationCoT,\n",
    "            temperature=0.0,\n",
    "        )\n",
    "        predictions_cot.append(result.categories)\n",
    "    except Exception as e:\n",
    "        print(f\"B≈ÇƒÖd: {e}\")\n",
    "        predictions_cot.append([])\n",
    "\n",
    "print(\"‚úÖ Gotowe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if golden_labels:\n",
    "    trial3 = evaluate_trial(\n",
    "        trial_name=f\"{MODEL_NAME} + Chain-of-Thought\",\n",
    "        model=MODEL_NAME,\n",
    "        prompt_variant=\"CoT\",\n",
    "        predictions=predictions_cot,\n",
    "        expected=golden_labels,\n",
    "        review_texts=golden_texts,\n",
    "        strategy=MatchStrategy.CONTAINS_ALL,\n",
    "    )\n",
    "    trial3.display()\n",
    "\n",
    "    # Por√≥wnanie z IteracjƒÖ 2 (za≈Çaduj trial2 je≈õli masz)\n",
    "    # compare_trials([trial2, trial3])\n",
    "    \n",
    "    print(f\"\\nüíæ Accuracy Iteracja 3: {trial3.summary.accuracy:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚úÖ Podsumowanie Iteracji 3\n",
    "\n",
    "**Czego siƒô nauczy≈Çe≈õ:**\n",
    "- Chain-of-Thought: dlaczego zmuszanie modelu do \"my≈õlenia\" poprawia jako≈õƒá\n",
    "- Zero-shot CoT vs Manual CoT\n",
    "- Dlaczego kolejno≈õƒá p√≥l w Pydantic ma znaczenie (reasoning ‚Üí categories)\n",
    "- Analiza b≈Çƒôd√≥w: kt√≥re recenzje model klasyfikuje ≈∫le i dlaczego\n",
    "\n",
    "**Kluczowa zasada:**  \n",
    "> Dla trudnych zada≈Ñ klasyfikacyjnych zawsze dodaj `reasoning: str` jako pierwsze pole w modelu.\n",
    "\n",
    "**Nastƒôpna iteracja:**  \n",
    "Few-shot learning - poka≈ºemy modelowi przyk≈Çady poprawnych klasyfikacji."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
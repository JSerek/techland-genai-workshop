{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üéØ Iteracja 4: Few-Shot Learning\n",
    "\n",
    "**Czas:** ~45 minut  \n",
    "**Poziom:** ≈öredniozaawansowany\n",
    "\n",
    "---\n",
    "\n",
    "## Cel iteracji\n",
    "\n",
    "Poprawiƒá accuracy klasyfikacji przez **pokazanie modelowi przyk≈Çad√≥w** poprawnych klasyfikacji - i sprawdziƒá ile przyk≈Çad√≥w naprawdƒô potrzebujemy.\n",
    "\n",
    "---\n",
    "\n",
    "## Teoria: Zero/One/Few-Shot Learning\n",
    "\n",
    "**Shot** = przyk≈Çad w prompcie.\n",
    "\n",
    "| Typ | Opis | Kiedy u≈ºywaƒá |\n",
    "|-----|------|--------------|\n",
    "| **Zero-shot** | Brak przyk≈Çad√≥w | Prosta klasyfikacja, gdy model dobrze zna dziedzinƒô |\n",
    "| **One-shot** | 1 przyk≈Çad | Gdy chcemy ustaliƒá format odpowiedzi |\n",
    "| **Few-shot** | 3-8 przyk≈Çad√≥w | Gdy model nie radzi sobie zero-shot, trudne kategorie |\n",
    "| **Many-shot** | 10+ przyk≈Çad√≥w | Bardzo specjalistyczne zadania, unikalne kategorie |\n",
    "\n",
    "### Jak dobieraƒá przyk≈Çady?\n",
    "\n",
    "Jako≈õƒá przyk≈Çad√≥w jest wa≈ºniejsza ni≈º ich liczba:\n",
    "\n",
    "1. **Reprezentatywno≈õƒá** - pokryj r√≥≈ºne typy recenzji (kr√≥tkie, d≈Çugie, wieloznaczne)\n",
    "2. **Trudne przypadki** - dodaj przyk≈Çady kt√≥re model klasyfikuje ≈∫le (analiza b≈Çƒôd√≥w!)\n",
    "3. **R√≥≈ºnorodno≈õƒá** - nie dawaj 5x tego samego wzorca\n",
    "4. **Graniczne przypadki** - przyk≈Çady miƒôdzy kategoriami (edge cases)\n",
    "5. **Kolejno≈õƒá ma znaczenie** - ostatnie przyk≈Çady majƒÖ wiƒôkszy wp≈Çyw (recency bias)\n",
    "\n",
    "### Few-shot vs Fine-tuning\n",
    "\n",
    "| | Few-shot | Fine-tuning |\n",
    "|--|---------|-------------|\n",
    "| Koszt | Darmowy | Drogi |\n",
    "| Szybko≈õƒá | Natychmiastowy | Godziny/dni treningu |\n",
    "| Wymagane dane | 3-10 przyk≈Çad√≥w | Setki/tysiƒÖce |\n",
    "| Jako≈õƒá | Dobra | Lepsza przy du≈ºych danych |\n",
    "| Elastyczno≈õƒá | ≈Åatwa zmiana | Trzeba trenowaƒá ponownie |\n",
    "\n",
    "> **Wniosek:** Zacznij zawsze od few-shot. Few-tuning tylko je≈õli few-shot nie wystarcza i masz du≈ºo danych."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Setup - ≈õrodowisko\n",
    "\n",
    "Ta kom√≥rka wykrywa czy jeste≈õ w **Google Colab** czy lokalnie, a nastƒôpnie:\n",
    "1. Klonuje repozytorium z GitHub (tylko Colab)\n",
    "2. Instaluje wymagane biblioteki\n",
    "3. Konfiguruje ≈õcie≈ºki import√≥w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "# Wykryj ≈õrodowisko\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "\n",
    "print(f\"{'üü° Google Colab' if IN_COLAB else 'üíª Lokalne ≈õrodowisko'}\")\n",
    "\n",
    "# ============================================================\n",
    "# KONFIGURACJA REPO (zmie≈Ñ URL na w≈Ça≈õciwe przed warsztatami)\n",
    "# ============================================================\n",
    "REPO_URL = \"https://github.com/JSerek/techland-genai-workshop.git\"\n",
    "REPO_DIR = Path(\"/content/szkolenie_techland\") if IN_COLAB else Path(\".\").resolve().parent\n",
    "# ============================================================\n",
    "\n",
    "if IN_COLAB:\n",
    "    if not REPO_DIR.exists():\n",
    "        print(f\"üì• Klonujƒô repo...\")\n",
    "        subprocess.run([\"git\", \"clone\", REPO_URL, str(REPO_DIR)], check=True)\n",
    "        print(\"‚úÖ Repo sklonowane\")\n",
    "    else:\n",
    "        print(\"üîÑ Aktualizujƒô repo (git pull)...\")\n",
    "        subprocess.run([\"git\", \"-C\", str(REPO_DIR), \"pull\"], check=True)\n",
    "\n",
    "    # Dodaj repo do sys.path\n",
    "    sys.path.insert(0, str(REPO_DIR))\n",
    "\n",
    "    # Zainstaluj zale≈ºno≈õci\n",
    "    print(\"üì¶ Instalujƒô biblioteki...\")\n",
    "    subprocess.run(\n",
    "        [sys.executable, \"-m\", \"pip\", \"install\", \"-r\", str(REPO_DIR / \"requirements.txt\"), \"-q\"],\n",
    "        check=True\n",
    "    )\n",
    "    print(\"‚úÖ Biblioteki zainstalowane\")\n",
    "else:\n",
    "    # Lokalnie: dodaj root projektu do sys.path\n",
    "    sys.path.insert(0, str(REPO_DIR))\n",
    "    print(f\"üìÇ ≈öcie≈ºka projektu: {REPO_DIR}\")\n",
    "\n",
    "print(\"\\n‚úÖ Setup zako≈Ñczony\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# üîë Konfiguracja API\n",
    "# W Google Colab: dodaj sekrety w menu po lewej (üîë ikona)\n",
    "#   Nazwy sekret√≥w: VERTEX_AI_API_KEY, VERTEX_AI_BASE_URL, MODEL_NAME\n",
    "#\n",
    "# Lokalnie: ustaw zmienne ≈õrodowiskowe lub wpisz warto≈õci bezpo≈õrednio\n",
    "# ============================================================\n",
    "\n",
    "if IN_COLAB:\n",
    "    from google.colab import userdata\n",
    "    API_KEY   = userdata.get(\"VERTEX_AI_API_KEY\")\n",
    "    BASE_URL  = userdata.get(\"VERTEX_AI_BASE_URL\")\n",
    "    MODEL_NAME = userdata.get(\"MODEL_NAME\") or \"google/gemini-2.5-flash-lite\"\n",
    "else:\n",
    "    import os\n",
    "    API_KEY   = os.environ.get(\"VERTEX_AI_API_KEY\", \"TODO: wklej API key\")\n",
    "    BASE_URL  = os.environ.get(\"VERTEX_AI_BASE_URL\", \"TODO: wklej endpoint URL\")\n",
    "    MODEL_NAME = os.environ.get(\"MODEL_NAME\", \"google/gemini-2.5-flash-lite\")\n",
    "\n",
    "# Walidacja\n",
    "if not API_KEY or API_KEY == \"TODO: wklej API key\":\n",
    "    print(\"‚ùå Brak API_KEY! Dodaj sekret 'VERTEX_AI_API_KEY' w Colab Secrets.\")\n",
    "elif not BASE_URL or BASE_URL == \"TODO: wklej endpoint URL\":\n",
    "    print(\"‚ùå Brak BASE_URL! Dodaj sekret 'VERTEX_AI_BASE_URL' w Colab Secrets.\")\n",
    "else:\n",
    "    print(f\"‚úÖ API skonfigurowane: {MODEL_NAME}\")\n",
    "    print(f\"   Endpoint: {BASE_URL[:60]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Konfiguracja klienta LLM - dane pobrane z Secrets w kom√≥rce powy≈ºej\n",
    "from src.utils.llm_client import create_client, LLMProvider\n",
    "\n",
    "PROVIDER = LLMProvider.VERTEX_AI  # Zmie≈Ñ je≈õli u≈ºywasz innego providera\n",
    "\n",
    "client = create_client(\n",
    "    provider=PROVIDER,\n",
    "    api_key=API_KEY,\n",
    "    base_url=BASE_URL,\n",
    ")\n",
    "print(f\"‚úÖ Klient LLM gotowy: {PROVIDER.value} / {MODEL_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Optional\n",
    "\n",
    "from src.evaluation.evaluator import evaluate_trial, compare_trials, MatchStrategy\n",
    "\n",
    "\n",
    "# Kategorie tematyczne\n",
    "CATEGORIES = [\n",
    "    \"gameplay\",       # Mechaniki rozgrywki, walka, parkour, sterowanie, balans\n",
    "    \"story\",          # Fabu≈Ça, postacie, dialogi, scenariusz\n",
    "    \"bugs\",           # Crashe, glitche, b≈Çƒôdy, problemy techniczne\n",
    "    \"performance\",    # FPS, lag, stuttering, optymalizacja ≈Çadowania\n",
    "    \"content\",        # Ilo≈õƒá contentu, d≈Çugo≈õƒá gry, powtarzalno≈õƒá\n",
    "    \"graphics\",       # Grafika, wizualia, animacje\n",
    "    \"audio\",          # Muzyka, d≈∫wiƒôki, voice acting\n",
    "    \"price\",          # Cena, warto≈õƒá za pieniƒÖdze, DLC\n",
    "]\n",
    "categories_str = ', '.join(f'\"{{c}}\"' for c in CATEGORIES)\n",
    "\n",
    "print('‚úÖ Biblioteki za≈Çadowane')\n",
    "print(f'Kategorie ({len(CATEGORIES)}): {categories_str}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = REPO_DIR / 'data'\n",
    "\n",
    "# Wczytaj golden dataset\n",
    "golden_path = DATA_DIR / 'evaluation' / 'golden_dataset.json'\n",
    "with open(golden_path) as f:\n",
    "    golden_data = json.load(f)\n",
    "\n",
    "golden_texts  = [item['review_text'] for item in golden_data]\n",
    "golden_labels = [item['labels']      for item in golden_data]\n",
    "\n",
    "print(f'‚úÖ Golden dataset: {len(golden_data)} recenzji')\n",
    "print(f'   Kategorie: {sorted(set(l for item in golden_data for l in item[\"labels\"]))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìã Golden Dataset\n",
    "\n",
    "Poni≈ºej 100 recenzji z przypisanymi kategoriami ‚Äî to nasz punkt odniesienia do ewaluacji.\n",
    "Model bƒôdzie klasyfikowa≈Ç te same recenzje, a my sprawdzimy czy jego wyniki zgadzajƒÖ siƒô z etykietami.\n",
    "\n",
    "| Kategoria | Opis |\n",
    "|-----------|------|\n",
    "| `gameplay` | Mechaniki rozgrywki, walka, parkour, sterowanie, balans |\n",
    "| `story` | Fabu≈Ça, postacie, dialogi, scenariusz |\n",
    "| `bugs` | Crashe, glitche, b≈Çƒôdy, problemy techniczne |\n",
    "| `performance` | FPS, lag, stuttering, optymalizacja |\n",
    "| `content` | Ilo≈õƒá contentu, d≈Çugo≈õƒá gry, powtarzalno≈õƒá |\n",
    "| `graphics` | Grafika, wizualia, animacje |\n",
    "| `audio` | Muzyka, d≈∫wiƒôki, voice acting |\n",
    "| `price` | Cena, warto≈õƒá za pieniƒÖdze, DLC |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "def show_golden_dataset(data: list[dict], max_text: int = 120) -> None:\n",
    "    \"\"\"Wy≈õwietla golden dataset jako sformatowanƒÖ tabelƒô HTML.\"\"\"\n",
    "    rows = []\n",
    "    for item in data:\n",
    "        text = item['review_text']\n",
    "        if len(text) > max_text:\n",
    "            text = text[:max_text] + '...'\n",
    "        # Ka≈ºda etykieta jako kolorowy badge\n",
    "        COLORS = {\n",
    "            'gameplay':    '#4C72B0', 'story':       '#DD8452',\n",
    "            'bugs':        '#55A868', 'performance': '#C44E52',\n",
    "            'content':     '#8172B2', 'graphics':    '#937860',\n",
    "            'audio':       '#DA8BC3', 'price':       '#8C8C8C',\n",
    "        }\n",
    "        badges = ' '.join(\n",
    "            f'<span style=\"background:{COLORS.get(l, \"#888\")};color:white;'\n",
    "            f'padding:2px 8px;border-radius:10px;font-size:11px;\">{l}</span>'\n",
    "            for l in item['labels']\n",
    "        )\n",
    "        rows.append(f'<tr><td style=\"text-align:center;color:#888;\">{item[\"id\"]}</td>'\n",
    "                    f'<td style=\"font-size:12px;\">{text}</td>'\n",
    "                    f'<td>{badges}</td></tr>')\n",
    "\n",
    "    html = f'''\n",
    "    <style>\n",
    "        .golden-table {{ border-collapse: collapse; width: 100%; font-family: sans-serif; }}\n",
    "        .golden-table th {{ background: #2d2d2d; color: white; padding: 8px 12px; text-align: left; }}\n",
    "        .golden-table td {{ padding: 6px 12px; border-bottom: 1px solid #eee; vertical-align: top; }}\n",
    "        .golden-table tr:hover td {{ background: #f9f9f9; }}\n",
    "    </style>\n",
    "    <table class=\"golden-table\">\n",
    "        <thead><tr>\n",
    "            <th style=\"width:40px\">#</th>\n",
    "            <th>Recenzja</th>\n",
    "            <th style=\"width:200px\">Kategorie</th>\n",
    "        </tr></thead>\n",
    "        <tbody>{''.join(rows)}</tbody>\n",
    "    </table>\n",
    "    '''\n",
    "    display(HTML(html))\n",
    "\n",
    "print(f'Golden dataset ‚Äî {len(golden_data)} recenzji:')\n",
    "show_golden_dataset(golden_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üèóÔ∏è Model Pydantic (z CoT z Iteracji 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReviewClassificationFewShot(BaseModel):\n",
    "    \"\"\"Klasyfikacja z CoT i few-shot examples.\"\"\"\n",
    "\n",
    "    reasoning: str = Field(\n",
    "        description=\"Analiza recenzji krok po kroku przed klasyfikacjƒÖ\"\n",
    "    )\n",
    "    categories: list[str] = Field(\n",
    "        description=f\"Finalna lista kategorii. Dozwolone: {CATEGORIES}\"\n",
    "    )\n",
    "\n",
    "print(\"‚úÖ Model zdefiniowany\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìù Definiowanie przyk≈Çad√≥w\n",
    "\n",
    "> üöß **TODO:** Uzupe≈Çnij przyk≈Çady po analizie danych i przygotowaniu golden dataset.\n",
    ">\n",
    "> **Wskaz√≥wka:** Przyk≈Çady powinny:\n",
    "> - Pokrywaƒá r√≥≈ºne typy recenzji\n",
    "> - Zawieraƒá trudne przypadki (wieloznaczne, graniczne)\n",
    "> - Pokazywaƒá recenzje z 1 kategoriƒÖ I z wieloma kategoriami"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# FEW-SHOT EXAMPLES\n",
    "# TODO: Uzupe≈Çnij po analizie danych\n",
    "# Format: lista s≈Çownik√≥w {\"review\": str, \"categories\": list[str]}\n",
    "# ============================================================\n",
    "\n",
    "FEW_SHOT_EXAMPLES = [\n",
    "    # Przyk≈Çadowy format (zastƒÖp prawdziwymi przyk≈Çadami):\n",
    "    # {\n",
    "    #     \"review\": \"The game crashes every time I try to enter a new area...\",\n",
    "    #     \"categories\": [\"bug\"]\n",
    "    # },\n",
    "    # {\n",
    "    #     \"review\": \"FPS drops to 20 in crowded areas, unplayable on my RTX 3080\",\n",
    "    #     \"categories\": [\"performance\"]\n",
    "    # },\n",
    "    # {\n",
    "    #     \"review\": \"Beautiful world, but the story feels rushed and shallow characters\",\n",
    "    #     \"categories\": [\"story\", \"graphics\"]\n",
    "    # },\n",
    "]\n",
    "\n",
    "print(f\"Zdefiniowano {len(FEW_SHOT_EXAMPLES)} przyk≈Çad√≥w.\")\n",
    "if not FEW_SHOT_EXAMPLES:\n",
    "    print(\"‚ö†Ô∏è  Lista jest pusta - uzupe≈Çnij FEW_SHOT_EXAMPLES!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_few_shot_examples_text(examples: list[dict]) -> str:\n",
    "    \"\"\"Buduje fragment promptu z przyk≈Çadami few-shot.\"\"\"\n",
    "    if not examples:\n",
    "        return \"\"\n",
    "\n",
    "    text = \"\\nPRZYK≈ÅADY POPRAWNYCH KLASYFIKACJI:\\n\"\n",
    "    for i, ex in enumerate(examples, 1):\n",
    "        cats = \", \".join(ex[\"categories\"])\n",
    "        text += f\"\\n[Przyk≈Çad {i}]\\n\"\n",
    "        text += f\"Recenzja: {ex['review']}\\n\"\n",
    "        text += f\"Kategorie: {cats}\\n\"\n",
    "    return text\n",
    "\n",
    "\n",
    "examples_text = build_few_shot_examples_text(FEW_SHOT_EXAMPLES)\n",
    "\n",
    "SYSTEM_PROMPT_FEW_SHOT = f\"\"\"Jeste≈õ ekspertem od analizy recenzji gier komputerowych.\n",
    "Klasyfikujesz recenzje do kategorii tematycznych.\n",
    "\n",
    "Dostƒôpne kategorie: {categories_str}\n",
    "{examples_text}\n",
    "Analizuj ka≈ºdƒÖ recenzjƒô krok po kroku, a nastƒôpnie podaj kategorie.\"\"\"\n",
    "\n",
    "USER_PROMPT = \"Recenzja do sklasyfikowania: {review_text}\"\n",
    "\n",
    "print(\"System prompt:\")\n",
    "print(SYSTEM_PROMPT_FEW_SHOT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß™ Trzy warianty: Zero-shot vs One-shot vs Few-shot\n",
    "\n",
    "Por√≥wnamy 3 pr√≥by jednocze≈õnie - to jest w≈Ça≈õnie ta funkcja `compare_trials()`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "def run_classification(system_prompt: str, texts: list[str]) -> list[list[str]]:\n",
    "    \"\"\"Uruchamia klasyfikacjƒô dla listy recenzji.\"\"\"\n",
    "    predictions = []\n",
    "    for text in tqdm(texts):\n",
    "        try:\n",
    "            result = client.chat.completions.create(\n",
    "                model=MODEL_NAME,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": system_prompt},\n",
    "                    {\"role\": \"user\", \"content\": USER_PROMPT.format(review_text=text)},\n",
    "                ],\n",
    "                response_model=ReviewClassificationFewShot,\n",
    "                temperature=0.0,\n",
    "            )\n",
    "            predictions.append(result.categories)\n",
    "        except Exception as e:\n",
    "            print(f\"B≈ÇƒÖd: {e}\")\n",
    "            predictions.append([])\n",
    "    return predictions\n",
    "\n",
    "\n",
    "texts_to_classify = golden_texts if golden_texts else review_texts[:10]\n",
    "\n",
    "# Wariant 1: Zero-shot (bez przyk≈Çad√≥w)\n",
    "SYSTEM_ZERO_SHOT = f\"\"\"Jeste≈õ ekspertem od analizy recenzji gier.\n",
    "Klasyfikuj recenzje do kategorii. Dostƒôpne: {categories_str}\n",
    "Analizuj krok po kroku.\"\"\"\n",
    "\n",
    "# Wariant 2: One-shot (1 przyk≈Çad)\n",
    "one_shot_ex = FEW_SHOT_EXAMPLES[:1] if FEW_SHOT_EXAMPLES else []\n",
    "SYSTEM_ONE_SHOT = SYSTEM_ZERO_SHOT + build_few_shot_examples_text(one_shot_ex)\n",
    "\n",
    "# Wariant 3: Few-shot (wszystkie przyk≈Çady)\n",
    "SYSTEM_FEW_SHOT = SYSTEM_PROMPT_FEW_SHOT\n",
    "\n",
    "print(\"Uruchamiam 3 warianty klasyfikacji...\")\n",
    "print(\"\\n[1/3] Zero-shot...\")\n",
    "preds_zero = run_classification(SYSTEM_ZERO_SHOT, texts_to_classify)\n",
    "\n",
    "print(\"\\n[2/3] One-shot...\")\n",
    "preds_one = run_classification(SYSTEM_ONE_SHOT, texts_to_classify)\n",
    "\n",
    "print(\"\\n[3/3] Few-shot...\")\n",
    "preds_few = run_classification(SYSTEM_FEW_SHOT, texts_to_classify)\n",
    "\n",
    "print(\"\\n‚úÖ Wszystkie warianty gotowe!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Por√≥wnanie wszystkich wariant√≥w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if golden_labels:\n",
    "    trial_zero = evaluate_trial(\n",
    "        trial_name=f\"Zero-shot\",\n",
    "        model=MODEL_NAME, prompt_variant=\"zero-shot + CoT\",\n",
    "        predictions=preds_zero, expected=golden_labels,\n",
    "        review_texts=golden_texts, strategy=MatchStrategy.CONTAINS_ALL,\n",
    "    )\n",
    "\n",
    "    trial_one = evaluate_trial(\n",
    "        trial_name=f\"One-shot\",\n",
    "        model=MODEL_NAME, prompt_variant=\"one-shot + CoT\",\n",
    "        predictions=preds_one, expected=golden_labels,\n",
    "        review_texts=golden_texts, strategy=MatchStrategy.CONTAINS_ALL,\n",
    "    )\n",
    "\n",
    "    trial_few = evaluate_trial(\n",
    "        trial_name=f\"Few-shot ({len(FEW_SHOT_EXAMPLES)} przyk≈Çad√≥w)\",\n",
    "        model=MODEL_NAME, prompt_variant=\"few-shot + CoT\",\n",
    "        predictions=preds_few, expected=golden_labels,\n",
    "        review_texts=golden_texts, strategy=MatchStrategy.CONTAINS_ALL,\n",
    "    )\n",
    "\n",
    "    # Por√≥wnanie - tabela + wykres\n",
    "    compare_trials([trial_zero, trial_one, trial_few])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üèÜ Por√≥wnanie WSZYSTKICH iteracji\n",
    "\n",
    "Zestawienie accuracy od Iteracji 1 do Iteracji 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Za≈Çaduj wyniki z poprzednich iteracji\n",
    "# Uzupe≈Çnij trial1, trial2, trial3 z poprzednich notebook√≥w\n",
    "# lub uruchom re-klasyfikacjƒô tutaj\n",
    "# ============================================================\n",
    "\n",
    "# Przyk≈Çad jak po≈ÇƒÖczyƒá wszystkie iteracje:\n",
    "# all_trials = [trial1, trial2, trial3, trial_few]\n",
    "# compare_trials(all_trials[:3])  # max 3 naraz w compare_trials\n",
    "\n",
    "# Mo≈ºesz te≈º pokazaƒá tabelƒô rƒôcznie:\n",
    "import pandas as pd\n",
    "\n",
    "# TODO: Uzupe≈Çnij po zako≈Ñczeniu wszystkich iteracji\n",
    "results_summary = pd.DataFrame([\n",
    "    {\"Iteracja\": \"1 - Zero-shot (raw)\", \"Podej≈õcie\": \"basic prompt\", \"Accuracy\": \"TODO%\"},\n",
    "    {\"Iteracja\": \"2 - Structured Output\", \"Podej≈õcie\": \"Pydantic + Instructor\", \"Accuracy\": \"TODO%\"},\n",
    "    {\"Iteracja\": \"3 - Chain-of-Thought\", \"Podej≈õcie\": \"CoT + Structured\", \"Accuracy\": \"TODO%\"},\n",
    "    {\"Iteracja\": \"4 - Few-shot\", \"Podej≈õcie\": f\"Few-shot ({len(FEW_SHOT_EXAMPLES)} ex) + CoT\", \"Accuracy\": \"TODO%\"},\n",
    "])\n",
    "\n",
    "print(\"PODSUMOWANIE WSZYSTKICH ITERACJI:\")\n",
    "print(results_summary.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üí° ƒÜwiczenie: Wybierz najlepszy prompt\n",
    "\n",
    "### Zadanie:\n",
    "Po≈ÇƒÖcz wszystko czego siƒô nauczy≈Çe≈õ - napisz prompt kt√≥ry osiƒÖga najwy≈ºszƒÖ accuracy.\n",
    "\n",
    "**Mo≈ºesz:**\n",
    "1. Zmieniƒá model (`MODEL_NAME`)\n",
    "2. Dodaƒá wiƒôcej/lepszych przyk≈Çad√≥w\n",
    "3. Ulepszy≈Ç instrukcje CoT\n",
    "4. Przetestowaƒá r√≥≈ºne strategie matchowania (`EXACT`, `CONTAINS_ANY`, `CONTAINS_ALL`)\n",
    "\n",
    "**üèÜ Kto ma najwy≈ºszƒÖ accuracy wygrywa!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# üñäÔ∏è  ƒÜWICZENIE: Tw√≥j najlepszy prompt\n",
    "# ============================================================\n",
    "\n",
    "MY_BEST_SYSTEM_PROMPT = \"\"\"\n",
    "# TODO: Napisz sw√≥j najlepszy prompt kombinujƒÖc wszystkie techniki\n",
    "\"\"\"\n",
    "\n",
    "MY_FEW_SHOT_EXAMPLES = [\n",
    "    # TODO: Dodaj najlepsze przyk≈Çady\n",
    "]\n",
    "\n",
    "# Uruchom i ewaluuj:\n",
    "# my_preds = run_classification(MY_BEST_SYSTEM_PROMPT, texts_to_classify)\n",
    "# my_trial = evaluate_trial(\n",
    "#     trial_name=\"M√≥j najlepszy prompt\",\n",
    "#     model=MODEL_NAME,\n",
    "#     prompt_variant=\"custom best\",\n",
    "#     predictions=my_preds,\n",
    "#     expected=golden_labels,\n",
    "#     review_texts=golden_texts,\n",
    "#     strategy=MatchStrategy.CONTAINS_ALL,\n",
    "# )\n",
    "# my_trial.display()\n",
    "\n",
    "print(\"Uzupe≈Çnij MY_BEST_SYSTEM_PROMPT i przetestuj!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üèÜ Podsumowanie ca≈Çego warsztatu\n",
    "\n",
    "### Czego siƒô nauczy≈Çe≈õ:\n",
    "\n",
    "| Iteracja | Technika | Kluczowy koncept |\n",
    "|----------|----------|-----------------|\n",
    "| 1 | Zero-shot prompting | System/user prompt, anatoma zapytania API |\n",
    "| 2 | Structured Output | Pydantic BaseModel, Instructor, walidacja |\n",
    "| 3 | Chain-of-Thought | reasoning ‚Üí categories, \"my≈õlenie\" modelu |\n",
    "| 4 | Few-shot learning | Przyk≈Çady w prompcie, dob√≥r przyk≈Çad√≥w |\n",
    "\n",
    "### Kluczowe zasady:\n",
    "\n",
    "1. **Zawsze waliduj output** - Pydantic + Instructor = brak niespodzianek\n",
    "2. **Testuj iteracyjnie** - zacznij prosto (zero-shot), dodawaj z≈Ço≈ºono≈õƒá tylko gdy potrzebna\n",
    "3. **Mierz dok≈Çadnie** - golden dataset + ewaluacja = prawdziwy postƒôp, nie tylko \"wydaje mi siƒô ≈ºe lepiej\"\n",
    "4. **Analizuj b≈Çƒôdy** - patrz CO model klasyfikuje ≈∫le, nie tylko ILE\n",
    "5. **Dokumentuj eksperymenty** - nadawaj nazwy pr√≥bom, zapisuj wyniki\n",
    "\n",
    "### Dalsze kroki:\n",
    "- **Fine-tuning** - gdy few-shot nie wystarcza i masz 100+ przyk≈Çad√≥w\n",
    "- **RAG** - gdy potrzebujesz zewnƒôtrznej wiedzy w odpowiedziach\n",
    "- **Agents** - gdy zadanie wymaga wielokrokowego rozumowania i narzƒôdzi"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
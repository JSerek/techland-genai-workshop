{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ—ï¸ Iteracja 2: Structured Output (Pydantic + Instructor)\n",
    "\n",
    "**Czas:** ~45 minut  \n",
    "**Poziom:** Podstawowy\n",
    "\n",
    "---\n",
    "\n",
    "## Cel iteracji\n",
    "\n",
    "ZastÄ…piÄ‡ kruche parsowanie surowych stringÃ³w **gwarantowanym, walidowanym outputem** przy uÅ¼yciu Pydantic i Instructor.\n",
    "\n",
    "---\n",
    "\n",
    "## Problem z Iteracji 1\n",
    "\n",
    "W poprzedniej iteracji model zwracaÅ‚ surowy tekst:\n",
    "\n",
    "```\n",
    "\"bug, performance\"  âœ… DziaÅ‚a\n",
    "\"Bug and Performance\"  âŒ RÃ³Å¼na wielkoÅ›Ä‡ liter\n",
    "\"The review mentions bugs and performance issues.\"  âŒ Zdanie zamiast etykiet\n",
    "\"[bug, performance]\"  âŒ Nawiasy kwadratowe\n",
    "```\n",
    "\n",
    "Parsowanie stringÃ³w jest **kruche** - kaÅ¼da zmiana formatu psuje kod.\n",
    "\n",
    "---\n",
    "\n",
    "## RozwiÄ…zanie: Pydantic + Instructor\n",
    "\n",
    "### Co to Pydantic?\n",
    "\n",
    "**Pydantic** to biblioteka do walidacji danych w Pythonie. Definiujesz model danych jako klasÄ™ Python, a Pydantic automatycznie:\n",
    "- Sprawdza typy danych\n",
    "- Waliduje wartoÅ›ci (np. czy liczba jest w zakresie 0-1)\n",
    "- Konwertuje typy gdy to moÅ¼liwe (string â†’ int)\n",
    "- Wyrzuca czytelne bÅ‚Ä™dy gdy walidacja siÄ™ nie powiÄ™dzie\n",
    "\n",
    "```python\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class ReviewClassification(BaseModel):\n",
    "    categories: list[str] = Field(description=\"Lista kategorii tematycznych\")\n",
    "    confidence: float = Field(ge=0, le=1, description=\"PewnoÅ›Ä‡ klasyfikacji 0-1\")\n",
    "```\n",
    "\n",
    "### Co to Instructor?\n",
    "\n",
    "**Instructor** to nakÅ‚adka na klientÃ³w LLM, ktÃ³ra:\n",
    "1. Dodaje instrukcje do promptu mÃ³wiÄ…ce modelowi, Å¼eby zwrÃ³ciÅ‚ JSON\n",
    "2. Parsuje JSON z odpowiedzi\n",
    "3. Waliduje JSON przez Pydantic\n",
    "4. JeÅ›li walidacja siÄ™ nie powiÄ™dzie - automatycznie pyta model ponownie z informacjÄ… o bÅ‚Ä™dzie\n",
    "\n",
    "```python\n",
    "import instructor\n",
    "from openai import OpenAI\n",
    "\n",
    "client = instructor.patch(OpenAI(), mode=instructor.Mode.MD_JSON)\n",
    "\n",
    "# Zamiast response.choices[0].message.content:\n",
    "result = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[...],\n",
    "    response_model=ReviewClassification,  # â† to jest nowe!\n",
    ")\n",
    "# result jest teraz obiektem ReviewClassification, nie stringiem!\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âš™ï¸ Setup - Å›rodowisko\n",
    "\n",
    "Ta komÃ³rka wykrywa czy jesteÅ› w **Google Colab** czy lokalnie, a nastÄ™pnie:\n",
    "1. Klonuje repozytorium z GitHub (tylko Colab)\n",
    "2. Instaluje wymagane biblioteki\n",
    "3. Konfiguruje Å›cieÅ¼ki importÃ³w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "# Wykryj Å›rodowisko\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "\n",
    "print(f\"{'ðŸŸ¡ Google Colab' if IN_COLAB else 'ðŸ’» Lokalne Å›rodowisko'}\")\n",
    "\n",
    "# ============================================================\n",
    "# KONFIGURACJA REPO (zmieÅ„ URL na wÅ‚aÅ›ciwe przed warsztatami)\n",
    "# ============================================================\n",
    "REPO_URL = \"https://github.com/JSerek/techland-genai-workshop.git\"\n",
    "REPO_DIR = Path(\"/content/szkolenie_techland\") if IN_COLAB else Path(\".\").resolve().parent\n",
    "# ============================================================\n",
    "\n",
    "if IN_COLAB:\n",
    "    if not REPO_DIR.exists():\n",
    "        print(f\"ðŸ“¥ KlonujÄ™ repo...\")\n",
    "        subprocess.run([\"git\", \"clone\", REPO_URL, str(REPO_DIR)], check=True)\n",
    "        print(\"âœ… Repo sklonowane\")\n",
    "    else:\n",
    "        print(\"ðŸ”„ AktualizujÄ™ repo (git pull)...\")\n",
    "        subprocess.run([\"git\", \"-C\", str(REPO_DIR), \"pull\"], check=True)\n",
    "\n",
    "    # Dodaj repo do sys.path\n",
    "    sys.path.insert(0, str(REPO_DIR))\n",
    "\n",
    "    # Zainstaluj zaleÅ¼noÅ›ci\n",
    "    print(\"ðŸ“¦ InstalujÄ™ biblioteki...\")\n",
    "    subprocess.run(\n",
    "        [sys.executable, \"-m\", \"pip\", \"install\", \"-r\", str(REPO_DIR / \"requirements.txt\"), \"-q\"],\n",
    "        check=True\n",
    "    )\n",
    "    print(\"âœ… Biblioteki zainstalowane\")\n",
    "else:\n",
    "    # Lokalnie: dodaj root projektu do sys.path\n",
    "    sys.path.insert(0, str(REPO_DIR))\n",
    "    print(f\"ðŸ“‚ ÅšcieÅ¼ka projektu: {REPO_DIR}\")\n",
    "\n",
    "print(\"\\nâœ… Setup zakoÅ„czony\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# ðŸ”‘ Konfiguracja API\n",
    "# W Google Colab: dodaj sekrety w menu po lewej (ðŸ”‘ ikona)\n",
    "#   Nazwy sekretÃ³w: VERTEX_AI_API_KEY, VERTEX_AI_BASE_URL, MODEL_NAME\n",
    "#\n",
    "# Lokalnie: ustaw zmienne Å›rodowiskowe lub wpisz wartoÅ›ci bezpoÅ›rednio\n",
    "# ============================================================\n",
    "\n",
    "if IN_COLAB:\n",
    "    from google.colab import userdata\n",
    "    API_KEY   = userdata.get(\"VERTEX_AI_API_KEY\")\n",
    "    BASE_URL  = userdata.get(\"VERTEX_AI_BASE_URL\")\n",
    "    MODEL_NAME = userdata.get(\"MODEL_NAME\") or \"google/gemini-2.5-flash-lite\"\n",
    "else:\n",
    "    import os\n",
    "    API_KEY   = os.environ.get(\"VERTEX_AI_API_KEY\", \"TODO: wklej API key\")\n",
    "    BASE_URL  = os.environ.get(\"VERTEX_AI_BASE_URL\", \"TODO: wklej endpoint URL\")\n",
    "    MODEL_NAME = os.environ.get(\"MODEL_NAME\", \"google/gemini-2.5-flash-lite\")\n",
    "\n",
    "# Walidacja\n",
    "if not API_KEY or API_KEY == \"TODO: wklej API key\":\n",
    "    print(\"âŒ Brak API_KEY! Dodaj sekret 'VERTEX_AI_API_KEY' w Colab Secrets.\")\n",
    "elif not BASE_URL or BASE_URL == \"TODO: wklej endpoint URL\":\n",
    "    print(\"âŒ Brak BASE_URL! Dodaj sekret 'VERTEX_AI_BASE_URL' w Colab Secrets.\")\n",
    "else:\n",
    "    print(f\"âœ… API skonfigurowane: {MODEL_NAME}\")\n",
    "    print(f\"   Endpoint: {BASE_URL[:60]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Konfiguracja klienta LLM - dane pobrane z Secrets w komÃ³rce powyÅ¼ej\n",
    "from src.utils.llm_client import create_client, LLMProvider\n",
    "\n",
    "PROVIDER = LLMProvider.VERTEX_AI  # ZmieÅ„ jeÅ›li uÅ¼ywasz innego providera\n",
    "\n",
    "client = create_client(\n",
    "    provider=PROVIDER,\n",
    "    api_key=API_KEY,\n",
    "    base_url=BASE_URL,\n",
    ")\n",
    "print(f\"âœ… Klient LLM gotowy: {PROVIDER.value} / {MODEL_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# ÅšcieÅ¼ki do danych (wzglÄ™dem root repo)\n",
    "DATA_DIR = REPO_DIR / \"data\"\n",
    "\n",
    "# PrÃ³bka recenzji\n",
    "df = pd.read_csv(DATA_DIR / \"processed\" / \"workshop_sample.csv\")\n",
    "review_texts = df[\"review_text\"].tolist()\n",
    "print(f\"âœ… ZaÅ‚adowano {len(review_texts)} recenzji\")\n",
    "\n",
    "# Golden dataset\n",
    "golden_path = DATA_DIR / \"evaluation\" / \"golden_dataset.json\"\n",
    "if golden_path.exists():\n",
    "    with open(golden_path) as f:\n",
    "        golden_data = json.load(f)\n",
    "    golden_texts = [item[\"review_text\"] for item in golden_data]\n",
    "    golden_labels = [item[\"labels\"] for item in golden_data]\n",
    "    print(f\"âœ… Golden dataset: {len(golden_data)} przykÅ‚adÃ³w\")\n",
    "else:\n",
    "    golden_texts, golden_labels = [], []\n",
    "    print(\"âš ï¸  Golden dataset nie znaleziony - ewaluacja niedostÄ™pna\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ” PorÃ³wnanie: Raw Output vs Structured Output\n",
    "\n",
    "Zobaczymy rÃ³Å¼nicÄ™ miÄ™dzy podejÅ›ciem z Iteracji 1 a Structured Output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- PodejÅ›cie z Iteracji 1 (raw string) ---\n",
    "def classify_raw(review_text: str) -> str:\n",
    "    \"\"\"Zwraca surowy string - trudny do parsowania.\"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=MODEL_NAME,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Klasyfikuj recenzjÄ™. ZwrÃ³Ä‡ kategorie oddzielone przecinkami.\"},\n",
    "            {\"role\": \"user\", \"content\": review_text},\n",
    "        ],\n",
    "        temperature=0.0,\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "test_review = review_texts[0]\n",
    "raw_result = classify_raw(test_review)\n",
    "print(f\"Raw output typ: {type(raw_result).__name__}\")\n",
    "print(f\"Raw output wartoÅ›Ä‡: '{raw_result}'\")\n",
    "print(f\"\\nCzy mogÄ™ uÅ¼yÄ‡ .categories? {hasattr(raw_result, 'categories')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ—ï¸ Definicja Pydantic Model\n",
    "\n",
    "Definiujemy strukturÄ™, ktÃ³rÄ… chcemy dostaÄ‡ z modelu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# TODO: UzupeÅ‚nij kategorie po analizie danych\n",
    "# ============================================================\n",
    "CATEGORIES = [\n",
    "    # \"performance\", \"bug\", \"story\", \"gameplay\", \"graphics\", \"audio\", \"price\", \"other\"\n",
    "]\n",
    "# ============================================================\n",
    "\n",
    "\n",
    "class ReviewClassification(BaseModel):\n",
    "    \"\"\"Wynik klasyfikacji tematycznej recenzji gry.\"\"\"\n",
    "\n",
    "    categories: list[str] = Field(\n",
    "        description=(\n",
    "            f\"Lista kategorii tematycznych z recenzji. \"\n",
    "            f\"Dozwolone wartoÅ›ci: {CATEGORIES}. \"\n",
    "            \"MoÅ¼e byÄ‡ jedna lub wiÄ™cej kategorii.\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "print(\"âœ… Model ReviewClassification zdefiniowany\")\n",
    "print(f\"Pola: {list(ReviewClassification.model_fields.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- PodejÅ›cie z Instructor (structured output) ---\n",
    "def classify_structured(review_text: str) -> ReviewClassification:\n",
    "    \"\"\"Zwraca walidowany obiekt Pydantic - zawsze poprawnej struktury.\"\"\"\n",
    "    categories_str = \", \".join(f'\"{c}\"' for c in CATEGORIES)\n",
    "\n",
    "    return client.chat.completions.create(\n",
    "        model=MODEL_NAME,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": f\"\"\"Klasyfikuj recenzjÄ™ gry do kategorii tematycznych.\n",
    "DostÄ™pne kategorie: {categories_str}\n",
    "Przypisz jednÄ… lub wiÄ™cej kategorii pasujÄ…cych do treÅ›ci recenzji.\"\"\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"Recenzja: {review_text}\"\n",
    "            },\n",
    "        ],\n",
    "        response_model=ReviewClassification,  # â† Instructor uÅ¼ywa tego!\n",
    "        temperature=0.0,\n",
    "    )\n",
    "\n",
    "\n",
    "structured_result = classify_structured(test_review)\n",
    "print(f\"Structured output typ: {type(structured_result).__name__}\")\n",
    "print(f\"WartoÅ›Ä‡: {structured_result}\")\n",
    "print(f\"\\nCzy mogÄ™ uÅ¼yÄ‡ .categories? {hasattr(structured_result, 'categories')}\")\n",
    "print(f\"Kategorie: {structured_result.categories}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ Ä†wiczenie: Rozszerz model o dodatkowe pola\n",
    "\n",
    "### Zadanie:\n",
    "Dodaj do modelu `ReviewClassification` pola `confidence` i `reasoning`. SprawdÅº jak wpÅ‚ywajÄ… na jakoÅ›Ä‡ klasyfikacji.\n",
    "\n",
    "> ðŸ’¡ **Dlaczego `reasoning` przed `categories`?**  \n",
    "> Zmuszanie modelu do najpierw wypisania rozumowania, a potem decyzji, to prosty sposÃ³b na **Chain-of-Thought** - model \"myÅ›li\" zanim odpowie. Poznamy to dokÅ‚adniej w Iteracji 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# ðŸ–Šï¸  Ä†WICZENIE: Rozszerz model\n",
    "# Dodaj pole 'reasoning' (str) i 'confidence' (float 0-1)\n",
    "# WAÅ»NE: reasoning powinno byÄ‡ PRZED categories\n",
    "# ============================================================\n",
    "\n",
    "class ReviewClassificationV2(BaseModel):\n",
    "    \"\"\"Rozszerzona klasyfikacja z reasoning i confidence.\"\"\"\n",
    "\n",
    "    # TODO: Dodaj pole 'reasoning' - opis co skÅ‚oniÅ‚o do takiej klasyfikacji\n",
    "    # reasoning: str = Field(description=\"...\")\n",
    "\n",
    "    categories: list[str] = Field(\n",
    "        description=f\"Lista kategorii. Dozwolone: {CATEGORIES}\"\n",
    "    )\n",
    "\n",
    "    # TODO: Dodaj pole 'confidence' - pewnoÅ›Ä‡ klasyfikacji 0-1\n",
    "    # confidence: float = Field(ge=0, le=1, description=\"...\")\n",
    "\n",
    "\n",
    "# Przetestuj rozszerzony model:\n",
    "# result_v2 = client.chat.completions.create(\n",
    "#     model=MODEL_NAME,\n",
    "#     messages=[...],\n",
    "#     response_model=ReviewClassificationV2,\n",
    "#     temperature=0.0,\n",
    "# )\n",
    "# print(result_v2)\n",
    "\n",
    "print(\"Zdefiniuj ReviewClassificationV2 i przetestuj!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“Š Klasyfikacja i ewaluacja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "texts_to_classify = golden_texts if golden_texts else review_texts[:10]\n",
    "\n",
    "print(f\"KlasyfikujÄ™ {len(texts_to_classify)} recenzji (structured output)...\")\n",
    "\n",
    "predictions = []\n",
    "for text in tqdm(texts_to_classify):\n",
    "    try:\n",
    "        result = classify_structured(text)\n",
    "        predictions.append(result.categories)\n",
    "    except Exception as e:\n",
    "        print(f\"BÅ‚Ä…d: {e}\")\n",
    "        predictions.append([])\n",
    "\n",
    "print(\"\\nâœ… Gotowe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if golden_labels:\n",
    "    trial2 = evaluate_trial(\n",
    "        trial_name=f\"{MODEL_NAME} + structured output\",\n",
    "        model=MODEL_NAME,\n",
    "        prompt_variant=\"structured output\",\n",
    "        predictions=predictions,\n",
    "        expected=golden_labels,\n",
    "        review_texts=golden_texts,\n",
    "        strategy=MatchStrategy.CONTAINS_ALL,\n",
    "    )\n",
    "    trial2.display()\n",
    "    print(f\"\\nðŸ’¾ Accuracy Iteracja 2: {trial2.summary.accuracy:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## âœ… Podsumowanie Iteracji 2\n",
    "\n",
    "**Czego siÄ™ nauczyÅ‚eÅ›:**\n",
    "- Definiowanie modeli danych z Pydantic (`BaseModel`, `Field`)\n",
    "- UÅ¼ywanie Instructor do gwarantowanego structured output\n",
    "- RÃ³Å¼nica miÄ™dzy surowym stringiem a walidowanym obiektem\n",
    "- Jak `reasoning` pole pomaga modelowi \"myÅ›leÄ‡\" (preview CoT)\n",
    "\n",
    "**Kluczowa zasada:**  \n",
    "> Zawsze uÅ¼ywaj Pydantic + Instructor w production-grade kodzie. Nigdy nie parsuj stringÃ³w z LLM rÄ™cznie.\n",
    "\n",
    "**NastÄ™pna iteracja:**  \n",
    "Explicitnymi instrukcjami Chain-of-Thought jeszcze bardziej poprawimy jakoÅ›Ä‡ klasyfikacji."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
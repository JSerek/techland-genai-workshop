{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìä Notebook 02: Przygotowanie danych\n",
    "\n",
    "**Cel:** Za≈Çadowanie zebranych recenzji, podstawowa eksploracja danych oraz przygotowanie pr√≥bki do ƒáwicze≈Ñ klasyfikacji.\n",
    "\n",
    "---\n",
    "\n",
    "## Co robimy w tym notebooku?\n",
    "\n",
    "1. ≈Åadujemy recenzje ze Steam (wynik scrapera z Notebook 01)\n",
    "2. Explorujemy dane - ile recenzji, jak wyglƒÖdajƒÖ, jakie majƒÖ cechy\n",
    "3. Przygotowujemy **pr√≥bkƒô roboczƒÖ** do ƒáwicze≈Ñ\n",
    "4. Tworzymy **golden dataset** - rƒôcznie etykietowanƒÖ pr√≥bkƒô do ewaluacji\n",
    "\n",
    "---\n",
    "\n",
    "> üí° **Golden dataset** to zbi√≥r przyk≈Çad√≥w z poprawnymi odpowiedziami, kt√≥ry s≈Çu≈ºy jako punkt odniesienia do oceny jako≈õci modelu. W tym warsztacie stworzymy go rƒôcznie na podstawie pr√≥bki recenzji."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Setup - ≈õrodowisko\n",
    "\n",
    "Ta kom√≥rka wykrywa czy jeste≈õ w **Google Colab** czy lokalnie, a nastƒôpnie:\n",
    "1. Klonuje repozytorium z GitHub (tylko Colab)\n",
    "2. Instaluje wymagane biblioteki\n",
    "3. Konfiguruje ≈õcie≈ºki import√≥w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "# Wykryj ≈õrodowisko\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "\n",
    "print(f\"{'üü° Google Colab' if IN_COLAB else 'üíª Lokalne ≈õrodowisko'}\")\n",
    "\n",
    "# ============================================================\n",
    "# KONFIGURACJA REPO (zmie≈Ñ URL na w≈Ça≈õciwe przed warsztatami)\n",
    "# ============================================================\n",
    "REPO_URL = \"https://github.com/JSerek/techland-genai-workshop.git\"\n",
    "REPO_DIR = Path(\"/content/szkolenie_techland\") if IN_COLAB else Path(\".\").resolve().parent\n",
    "# ============================================================\n",
    "\n",
    "if IN_COLAB:\n",
    "    if not REPO_DIR.exists():\n",
    "        print(f\"üì• Klonujƒô repo...\")\n",
    "        subprocess.run([\"git\", \"clone\", REPO_URL, str(REPO_DIR)], check=True)\n",
    "        print(\"‚úÖ Repo sklonowane\")\n",
    "    else:\n",
    "        print(\"üîÑ Aktualizujƒô repo (git pull)...\")\n",
    "        subprocess.run([\"git\", \"-C\", str(REPO_DIR), \"pull\"], check=True)\n",
    "\n",
    "    # Dodaj repo do sys.path\n",
    "    sys.path.insert(0, str(REPO_DIR))\n",
    "\n",
    "    # Zainstaluj zale≈ºno≈õci\n",
    "    print(\"üì¶ Instalujƒô biblioteki...\")\n",
    "    subprocess.run(\n",
    "        [sys.executable, \"-m\", \"pip\", \"install\", \"-r\", str(REPO_DIR / \"requirements.txt\"), \"-q\"],\n",
    "        check=True\n",
    "    )\n",
    "    print(\"‚úÖ Biblioteki zainstalowane\")\n",
    "else:\n",
    "    # Lokalnie: dodaj root projektu do sys.path\n",
    "    sys.path.insert(0, str(REPO_DIR))\n",
    "    print(f\"üìÇ ≈öcie≈ºka projektu: {REPO_DIR}\")\n",
    "\n",
    "print(\"\\n‚úÖ Setup zako≈Ñczony\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# üîë Konfiguracja API\n",
    "# W Google Colab: dodaj sekrety w menu po lewej (üîë ikona)\n",
    "#   Nazwy sekret√≥w: VERTEX_AI_API_KEY, VERTEX_AI_BASE_URL, MODEL_NAME\n",
    "#\n",
    "# Lokalnie: ustaw zmienne ≈õrodowiskowe lub wpisz warto≈õci bezpo≈õrednio\n",
    "# ============================================================\n",
    "\n",
    "if IN_COLAB:\n",
    "    from google.colab import userdata\n",
    "    API_KEY   = userdata.get(\"VERTEX_AI_API_KEY\")\n",
    "    BASE_URL  = userdata.get(\"VERTEX_AI_BASE_URL\")\n",
    "    MODEL_NAME = userdata.get(\"MODEL_NAME\") or \"google/gemini-2.5-flash-lite\"\n",
    "else:\n",
    "    import os\n",
    "    API_KEY   = os.environ.get(\"VERTEX_AI_API_KEY\", \"TODO: wklej API key\")\n",
    "    BASE_URL  = os.environ.get(\"VERTEX_AI_BASE_URL\", \"TODO: wklej endpoint URL\")\n",
    "    MODEL_NAME = os.environ.get(\"MODEL_NAME\", \"google/gemini-2.5-flash-lite\")\n",
    "\n",
    "# Walidacja\n",
    "if not API_KEY or API_KEY == \"TODO: wklej API key\":\n",
    "    print(\"‚ùå Brak API_KEY! Dodaj sekret 'VERTEX_AI_API_KEY' w Colab Secrets.\")\n",
    "elif not BASE_URL or BASE_URL == \"TODO: wklej endpoint URL\":\n",
    "    print(\"‚ùå Brak BASE_URL! Dodaj sekret 'VERTEX_AI_BASE_URL' w Colab Secrets.\")\n",
    "else:\n",
    "    print(f\"‚úÖ API skonfigurowane: {MODEL_NAME}\")\n",
    "    print(f\"   Endpoint: {BASE_URL[:60]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ≈Åadowanie danych\n",
    "\n",
    "Dane zosta≈Çy wcze≈õniej zebrane za pomocƒÖ scrapera Steam (Notebook 01).\n",
    "≈Åadujemy je z pliku CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# KONFIGURACJA - zmie≈Ñ ≈õcie≈ºkƒô do pliku z danymi\n",
    "# ============================================================\n",
    "DATA_PATH = \"../data/raw/steam_reviews.csv\"  # TODO: zaktualizuj nazwƒô pliku\n",
    "# ============================================================\n",
    "\n",
    "data_file = Path(DATA_PATH)\n",
    "\n",
    "if not data_file.exists():\n",
    "    print(f\"‚ùå Nie znaleziono pliku: {DATA_PATH}\")\n",
    "    print(\"Upewnij siƒô ≈ºe uruchomi≈Çe≈õ Notebook 01 i dane zosta≈Çy zapisane.\")\n",
    "else:\n",
    "    df = pd.read_csv(data_file)\n",
    "    print(f\"‚úÖ Za≈Çadowano {len(df):,} recenzji\")\n",
    "    print(f\"Kolumny: {list(df.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Eksploracja danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Podstawowe statystyki\n",
    "print(\"=\" * 50)\n",
    "print(\"PODSTAWOWE STATYSTYKI\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Liczba recenzji:          {len(df):,}\")\n",
    "print(f\"Pozytywne:                {df['sentiment'].value_counts().get('positive', 0):,}\")\n",
    "print(f\"Negatywne:                {df['sentiment'].value_counts().get('negative', 0):,}\")\n",
    "print(f\"\\n≈örednia d≈Çugo≈õƒá recenzji: {df['review_text'].str.len().mean():.0f} znak√≥w\")\n",
    "print(f\"Mediana d≈Çugo≈õci:         {df['review_text'].str.len().median():.0f} znak√≥w\")\n",
    "print(f\"Max d≈Çugo≈õƒá:              {df['review_text'].str.len().max():,} znak√≥w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wy≈õwietl przyk≈Çadowe recenzje\n",
    "print(\"\\nPRZYK≈ÅADOWE RECENZJE:\")\n",
    "print(\"=\" * 50)\n",
    "for i, row in df.sample(5, random_state=42).iterrows():\n",
    "    print(f\"[{row['sentiment'].upper()}] {row['review_text'][:200]}...\")\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rozk≈Çad d≈Çugo≈õci recenzji\n",
    "df[\"review_length\"] = df[\"review_text\"].str.len()\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Histogram d≈Çugo≈õci\n",
    "axes[0].hist(df[\"review_length\"].clip(upper=2000), bins=40, color=\"#4C72B0\", edgecolor=\"white\")\n",
    "axes[0].set_xlabel(\"D≈Çugo≈õƒá recenzji (znaki)\")\n",
    "axes[0].set_ylabel(\"Liczba recenzji\")\n",
    "axes[0].set_title(\"Rozk≈Çad d≈Çugo≈õci recenzji\")\n",
    "\n",
    "# D≈Çugo≈õƒá per sentyment\n",
    "df.boxplot(column=\"review_length\", by=\"sentiment\", ax=axes[1])\n",
    "axes[1].set_title(\"D≈Çugo≈õƒá recenzji per sentyment\")\n",
    "axes[1].set_xlabel(\"Sentyment\")\n",
    "axes[1].set_ylabel(\"D≈Çugo≈õƒá (znaki)\")\n",
    "plt.suptitle(\"\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Przygotowanie pr√≥bki roboczej\n",
    "\n",
    "Do ƒáwicze≈Ñ klasyfikacji potrzebujemy **zarzƒÖdzalnej pr√≥bki** recenzji.\n",
    "Na warsztacie bƒôdziemy u≈ºywaƒá ok. 50-100 recenzji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# KONFIGURACJA pr√≥bki\n",
    "# ============================================================\n",
    "SAMPLE_SIZE = 50           # Liczba recenzji do ƒáwicze≈Ñ\n",
    "RANDOM_SEED = 42           # Dla reprodukowalno≈õci\n",
    "MIN_REVIEW_LENGTH = 50     # Minimalna d≈Çugo≈õƒá recenzji (filtrowujemy zbyt kr√≥tkie)\n",
    "MAX_REVIEW_LENGTH = 1000   # Maksymalna d≈Çugo≈õƒá (opcjonalnie)\n",
    "# ============================================================\n",
    "\n",
    "# Filtrowanie\n",
    "df_filtered = df[\n",
    "    (df[\"review_length\"] >= MIN_REVIEW_LENGTH) &\n",
    "    (df[\"review_length\"] <= MAX_REVIEW_LENGTH)\n",
    "].copy()\n",
    "\n",
    "print(f\"Po filtrowaniu: {len(df_filtered):,} recenzji\")\n",
    "\n",
    "# Pr√≥bka\n",
    "df_sample = df_filtered.sample(n=min(SAMPLE_SIZE, len(df_filtered)), random_state=RANDOM_SEED)\n",
    "df_sample = df_sample.reset_index(drop=True)\n",
    "\n",
    "print(f\"Pr√≥bka robocza: {len(df_sample)} recenzji\")\n",
    "df_sample[[\"sentiment\", \"review_text\"]].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zapisz pr√≥bkƒô\n",
    "sample_path = Path(\"../data/processed/workshop_sample.csv\")\n",
    "sample_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "df_sample.to_csv(sample_path, index=False)\n",
    "print(f\"‚úÖ Pr√≥bka zapisana: {sample_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Golden Dataset\n",
    "\n",
    "> üöß **TODO po analizie danych**\n",
    ">\n",
    "> Ten sekcja zostanie uzupe≈Çniona po:\n",
    "> 1. Okre≈õleniu kategorii tematycznych (analiza jako≈õciowa recenzji)\n",
    "> 2. Rƒôcznym etykietowaniu pr√≥bki recenzji\n",
    ">\n",
    "> Kategorie tematyczne bƒôdƒÖ wynikiem analizy ‚Äî np. `bug`, `performance`, `story`, `gameplay`, `graphics` itd.\n",
    "\n",
    "**Format golden dataset:**\n",
    "```json\n",
    "[\n",
    "  {\n",
    "    \"review_text\": \"The game crashes every 20 minutes...\",\n",
    "    \"labels\": [\"bug\", \"performance\"]\n",
    "  },\n",
    "  {\n",
    "    \"review_text\": \"Amazing story but repetitive gameplay...\",\n",
    "    \"labels\": [\"story\", \"gameplay\"]\n",
    "  }\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# TODO: Uzupe≈Çnij po analizie danych\n",
    "# ============================================================\n",
    "\n",
    "# ≈öcie≈ºka do golden dataset\n",
    "GOLDEN_DATASET_PATH = \"../data/evaluation/golden_dataset.json\"  # TODO\n",
    "\n",
    "# Kategorie tematyczne\n",
    "CATEGORIES = [\n",
    "    # TODO: uzupe≈Çnij po analizie danych\n",
    "    # Przyk≈Çady: \"bug\", \"performance\", \"story\", \"gameplay\", \"graphics\", \"price\", \"other\"\n",
    "]\n",
    "\n",
    "print(\"‚ö†Ô∏è  Golden dataset nie jest jeszcze zdefiniowany.\")\n",
    "print(f\"Po uzupe≈Çnieniu wczytaj go z: {GOLDEN_DATASET_PATH}\")\n",
    "\n",
    "# Tak bƒôdzie wyglƒÖda≈Ço wczytanie golden dataset:\n",
    "# golden_path = Path(GOLDEN_DATASET_PATH)\n",
    "# if golden_path.exists():\n",
    "#     with open(golden_path) as f:\n",
    "#         golden_data = json.load(f)\n",
    "#     golden_texts = [item[\"review_text\"] for item in golden_data]\n",
    "#     golden_labels = [item[\"labels\"] for item in golden_data]\n",
    "#     print(f\"‚úÖ Golden dataset: {len(golden_data)} przyk≈Çad√≥w\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚úÖ Podsumowanie\n",
    "\n",
    "Po uruchomieniu tego notebooka masz:\n",
    "- **`data/processed/workshop_sample.csv`** - pr√≥bka recenzji do ƒáwicze≈Ñ\n",
    "- Podstawowe rozumienie struktury danych\n",
    "\n",
    "**Nastƒôpny krok:** Notebook 03 - Iteracja 1: Podstawowe promptowanie"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}